\section{Performance Metrics}

\subsection{Mean Squared Error}

\begin{definition}[Mean Squared Error]
A common performance metric for regression problems is the \textbf{mean squared error (MSE)}:
\[ \text{MSE} = \frac{1}{N} \sum_{i=1}^N (y_i - w^\top x_i)^2 \]

This is similar to the squared loss but with two differences:
\begin{itemize}
    \item MSE can be used for the validation set and test set in addition to the training set
    \item MSE measures the mean over all the examples in the set, not the sum
\end{itemize}
\end{definition}

\begin{remark}[Root Mean Squared Error]
Instead of using MSE, it is more common to use the \textbf{root mean squared error (RMSE)}, which is the square root of MSE, to bring it back to the same level of prediction error for easier interpretation.

For example, if the unit of $y$ is in meters (m), both the squared error and MSE are in $m^2$, but RMSE is in $m$.
\end{remark}

\subsection{RÂ² Score}

\begin{definition}[Coefficient of Determination]
Another commonly used performance metric for regression problems is the \textbf{coefficient of determination} or \textbf{$R^2$ score}:
\[ R^2 = 1 - \frac{\sum_{i=1}^N (y_i - w^\top x_i)^2}{\sum_{i=1}^N (y_i - \bar{y})^2} = 1 - \frac{\frac{1}{N}\sum_{i=1}^N (y_i - w^\top x_i)^2}{\frac{1}{N}\sum_{i=1}^N (y_i - \bar{y})^2} = 1 - \frac{\text{MSE}}{\text{variance}} \]

where
\[ \bar{y} = \frac{1}{N} \sum_{i=1}^N y_i \]
\end{definition}

\begin{property}[Properties of $R^2$ Score]
\begin{itemize}
    \item The best possible $R^2$ score is 1 when the corresponding MSE is 0
    \item When the model always predicts the mean value of $y$, the $R^2$ score will be equal to 0
    \item Negative values are also possible because the model can have arbitrarily large MSE
\end{itemize}
\end{property}

\begin{remark}[Interpretation]
The $R^2$ score represents the proportion of variance in the dependent variable that is predictable from the independent variables. It provides a measure of how well observed outcomes are replicated by the model.
\end{remark}
