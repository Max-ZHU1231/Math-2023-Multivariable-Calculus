\section{Model Capacity, Overfitting and Underfitting}

\subsection{Hypothesis Space and Capacity}

\begin{definition}[Hypothesis Space]
The \textbf{hypothesis space} of a machine learning algorithm/model is the set of functions that it is allowed to select as being the solution.

The ``size'' of the hypothesis space is called the \textbf{capacity} of the model.
\end{definition}

\begin{remark}
For polynomial regression, the larger the degree $d$, the higher the model capacity. Higher model capacity implies better fit to training data.
\end{remark}

\subsection{Generalization Error}

\begin{definition}[Training vs Test Error]
A machine learning model is trained to perform well on the training examples. But what we really care about is that it must perform well on new and previously unseen examples. This is called \textbf{generalization}.

We use the error on a test set to measure how well a model generalizes:
\[ L^{(\text{test})}(w) = \frac{1}{N^{(\text{test})}} \|y^{(\text{test})} - X^{(\text{test})}w\|_2^2 \]
This is called the \textbf{test error} or the \textbf{generalization error}.

In contrast, the \textbf{training error} is:
\[ L^{(\text{train})}(w) = \frac{1}{N^{(\text{train})}} \|y^{(\text{train})} - X^{(\text{train})}w\|_2^2 \]
\end{definition}

\begin{property}[Relationship Between Training and Test Error]
The test and training errors are related because we assume both training and test data are iid samples of an underlying data generation process $p(x, y)$.

However, small training error does not always imply small generalization error. The generalization error is usually larger than training error because the model parameters are selected to minimize the training error.
\end{property}

\begin{remark}
To build a good model, we need to:
\begin{enumerate}
    \item Make the training error small, and
    \item Make the gap between the test and training error small
\end{enumerate}
\end{remark}

\subsection{Overfitting and Underfitting}

Training and test error behave differently as model capacity increases.

\begin{definition}[Underfitting and Overfitting]
\begin{itemize}
    \item \textbf{Underfitting regime}: At the left end of the capacity spectrum, training error and generalization error are both high. The model is too simple to capture the underlying pattern.
    
    \item \textbf{Optimal capacity}: As we increase capacity, training error decreases and generalization improves.
    
    \item \textbf{Overfitting regime}: Eventually, the gap between training and generalization error increases. The size of this gap outweighs the decrease in training error. Capacity is too large, and the model is fitting noise in the training data.
\end{itemize}
\end{definition}

\begin{remark}
Choosing a model with the appropriate capacity is important. This can be achieved by either \textbf{validation} or \textbf{regularization}.
\end{remark}

\subsection{Validation}

\begin{definition}[Validation Method]
Model capacity is usually determined by hyperparameters such as the order $d$ of polynomial in polynomial regression.

\textbf{Validation} is a common method for determining the values of hyperparameters:
\begin{enumerate}
    \item Randomly divide the training set into two disjoint subsets:
    \begin{itemize}
        \item One subset is still called the \textbf{training set}
        \item The other is called the \textbf{validation set} or \textbf{held-out set}
    \end{itemize}
    
    \item To determine the value of hyperparameter $d$:
    \begin{itemize}
        \item Try a set of possible values
        \item For each possible value of $d$, train the model on the training set and measure the error on the validation set (called \textbf{validation error})
        \item Pick the value that has the minimum validation error
    \end{itemize}
\end{enumerate}
\end{definition}

\begin{remark}[Data Split Guidelines]
How to divide training data into training set and validation set?
\begin{itemize}
    \item The larger the training set, the better the hypothesis (i.e., $y = f(x)$)
    \item The larger the validation set, the more accurate the validation error estimation
    \item Typically, withhold 20\% of the available examples for the validation set, using the other 80\% for training
\end{itemize}
\end{remark}

\subsection{Cross Validation}

When data is limited, withholding part of it for validation set reduces even further the number of examples available for training, and error estimates can have large variance.

\begin{definition}[K-Fold Cross Validation]
An alternative is to use \textbf{cross validation}:
\begin{enumerate}
    \item The $N$ available examples are partitioned into $k$ disjoint subsets, each of size $N/k$
    
    \item The learning procedure is then run $k$ times, each time:
    \begin{itemize}
        \item Using one of these subsets as the validation set, and
        \item Combining the other subsets for the training set
    \end{itemize}
    
    \item Average the performance on the validation sets over the $k$ runs
    
    \item Typically $k = 10$
\end{enumerate}
\end{definition}

\subsection{Regularization}

Instead of using validation to pick an appropriate value for the order $d$ of polynomial, we can start with a large $d$, and hence a large hypothesis space. Then we use regularization to pick an appropriate solution from that space so as to avoid overfitting.

\begin{remark}[Setup]
Suppose the non-linear transformation $\phi(x)$ has $K$ components.

Example: In $y = f(x) = w_0 + w_1x_1 + w_2x_2 + w_3x_1^2 + w_4x_1x_2 + w_5x_2^2$, we have $K = 5$ and $\phi = (x_1, x_2, x_1^2, x_1x_2, x_2^2)$.

Let $w = (w_1, w_2, \ldots, w_K)^\top$. The bias $w_0$ is separated from $w$.
\end{remark}

\begin{definition}[Regularized Error Function]
The error function without regularization is:
\[ L(w, w_0) = \frac{1}{N} \sum_{i=1}^N (y_i - (w_0 + w^\top \phi(x_i)))^2 \]

The error function with regularization is:
\[ L(w, w_0) = \frac{1}{N} \sum_{i=1}^N (y_i - (w_0 + w^\top \phi(x_i)))^2 + \lambda \|w\|_2^2 \]

where $\lambda \geq 0$ is a hyperparameter chosen ahead of time that controls the strength of our preference for smaller weights.
\end{definition}

\begin{property}[Weight Decay]
Minimizing $L(w, w_0)$ gives us a solution that puts significant weights on a small number of features. This is called \textbf{weight decay}.

This way, we get a solution that effectively uses a small number of features and hence does not suffer from overfitting.

Note that $w_0$ is not regularized as it does not influence model complexity.
\end{property}

\begin{example}[Regularization Effect]
The true function is quadratic, and we use polynomials with degree 9.
\begin{itemize}
    \item With $\lambda$ approaching zero, the degree-9 polynomial overfits significantly
    \item With very large $\lambda$, we can force the model to learn a function with no slope at all
    \item With a medium value of $\lambda$, the learning algorithm recovers a curve with the right general shape
\end{itemize}
\end{example}

\subsection{Ridge Regression}

\begin{theorem}[Ridge Regression Solution]
Regression using the following error function is called \textbf{ridge regression} or \textbf{penalized least squares}:
\[ L(w, w_0) = \frac{1}{N} \sum_{i=1}^N (y_i - (w_0 + w^\top \phi(x_i)))^2 + \lambda \|w\|_2^2 \]

The penalized least squares solution is:
\[ \hat{w}_{\text{ridge}} = (\lambda I_K + X^\top X)^{-1}X^\top y \]
where $I_K$ is the $K$-dimensional identity matrix. The larger the regularization constant $\lambda$, the smaller the weights.

Compare this with the ordinary least squares solution:
\[ \hat{w} = (X^\top X)^{-1}X^\top y \]
\end{theorem}

\subsection{LASSO}

\begin{definition}[LASSO]
By using L2 regularization, Ridge regression shrinks large regression coefficients in order to reduce overfitting.

In contrast, \textbf{LASSO} (least absolute shrinkage and selection operator) forces certain coefficients to zero, and thereby chooses a sparser model that uses only a subset of the features.

LASSO uses L1 regularization:
\[ L(w, w_0) = \frac{1}{N} \sum_{i=1}^N (y_i - (w_0 + w^\top \phi(x_i)))^2 + \lambda \|w\|_1 \]
\end{definition}

\begin{remark}[LASSO vs Ridge]
Red circles represent contours of the error function; Blue lines represent contours of the regularization term; Minimum is at the center.
\begin{itemize}
    \item With LASSO, the sum error$(w)$ + regularization$(w)$ usually achieves minimum at some corners, which lie on the axes. This means some of the weights are set to 0, and the corresponding features not used.
    
    \item With Ridge regression, the minimum is usually not achieved on the axes. Weights are seldom 0.
\end{itemize}
\end{remark}
